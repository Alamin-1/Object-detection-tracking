{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import os\n",
    "# comment out below line to enable tensorflow logging outputs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import time\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import core.utils as utils\n",
    "from core.yolov4 import filter_boxes\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from core.config import cfg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from imutils.video import FPS\n",
    "# deep sort imports\n",
    "from deep_sort import preprocessing, nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from tools import generate_detections as gdet\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(anchors_path):\n",
    "    anchors = np.array(anchors_path)\n",
    "    return anchors.reshape(3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(FLAGS):\n",
    "    STRIDES = np.array(cfg.YOLO.STRIDES)\n",
    "    if FLAGS == 'yolov4':\n",
    "        ANCHORS = get_anchors(cfg.YOLO.ANCHORS)\n",
    "    XYSCALE = cfg.YOLO.XYSCALE\n",
    "    NUM_CLASS = len(utils.read_class_names(cfg.YOLO.CLASSES))\n",
    "    return STRIDES, ANCHORS, NUM_CLASS, XYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.4\n",
    "nn_budget = None\n",
    "nms_max_overlap = 1.0\n",
    "with open(\"data/classes/cus_tracking.names\", \"r\", encoding='utf-8') as f:\n",
    "    tracked_classes = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_new_1.avi', fourcc, 20.0, (640,480))    \n",
    "    \n",
    "class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
    "# initialize deep sort model\n",
    "model_filename = 'model_data/mars-small128.pb'\n",
    "encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "# calculate cosine distance metric\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "# initialize tracker\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "\n",
    "# load configuration for object detector\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "STRIDES, ANCHORS, NUM_CLASS, XYSCALE = load_config('yolov4')\n",
    "\n",
    "input_size = 416\n",
    "video_path = './data/cut_1.mp4'\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load('./checkpoints/yolov4-416', tags=[tag_constants.SERVING])\n",
    "infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "vid = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "pv_1_xy, pv_1_lbl = [],[]\n",
    "wnd_lbl, wnd_xy = [],[]\n",
    "frame_num = 0\n",
    "fps = FPS().start()\n",
    "while True:\n",
    "    grabbed, frame = vid.read()\n",
    "    if grabbed==True:\n",
    "        image = Image.fromarray(frame)\n",
    "        frame_size = frame.shape[:2]\n",
    "        image_data = cv2.resize(frame, (input_size, input_size))\n",
    "        image_data = image_data / 255.\n",
    "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "        start_time = time.time()\n",
    "        batch_data = tf.constant(image_data)\n",
    "        pred_bbox = infer(batch_data)\n",
    "        for key, value in pred_bbox.items():\n",
    "            boxes = value[:, :, 0:4]\n",
    "            pred_conf = value[:, :, 4:]\n",
    "\n",
    "        boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "            boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "            scores=tf.reshape(\n",
    "                pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "            max_output_size_per_class=50,\n",
    "            max_total_size=50,\n",
    "            iou_threshold=0.45,\n",
    "            score_threshold=0.5)    \n",
    "\n",
    "        # convert data to numpy arrays and slice out unused elements\n",
    "        num_objects = valid_detections.numpy()[0]\n",
    "        bboxes = boxes.numpy()[0]\n",
    "        bboxes = bboxes[0:int(num_objects)]\n",
    "        scores = scores.numpy()[0]\n",
    "        scores = scores[0:int(num_objects)]\n",
    "        classes = classes.numpy()[0]\n",
    "        classes = classes[0:int(num_objects)]\n",
    "\n",
    "        # format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n",
    "        original_h, original_w, _ = frame.shape\n",
    "        bboxes = utils.format_boxes(bboxes, original_h, original_w)\n",
    "\n",
    "        # store all predictions in one parameter for simplicity when calling functions\n",
    "        pred_bbox = [bboxes, scores, classes, num_objects]\n",
    "        names, deleted_indx = [], []\n",
    "        for i in range(num_objects):\n",
    "            class_indx = int(classes[i])\n",
    "            class_name = class_names[class_indx]\n",
    "            if class_name not in tracked_classes:\n",
    "                deleted_indx.append(i)\n",
    "            else:\n",
    "                names.append(class_name)\n",
    "        names = np.array(names)\n",
    "        count = len(names)\n",
    "\n",
    "        # delete detections that are not in tracked_classes\n",
    "        bboxes = np.delete(bboxes, deleted_indx, axis=0)\n",
    "        scores = np.delete(scores, deleted_indx, axis=0)\n",
    "\n",
    "        # encode yolo detections and feed to tracker\n",
    "        features = encoder(frame, bboxes)\n",
    "        detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n",
    "\n",
    "\n",
    "        #initialize color map\n",
    "        cmap = plt.get_cmap('tab20b')\n",
    "        colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "        # run non-maxima supression\n",
    "        boxs = np.array([d.tlwh for d in detections])\n",
    "        scores = np.array([d.confidence for d in detections])\n",
    "        classes = np.array([d.class_name for d in detections])\n",
    "        indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "        detections = [detections[i] for i in indices]\n",
    "\n",
    "        # Call the tracker\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "        # update tracks\n",
    "        cr_xy,cr_lbl = [],[]\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            bbox = track.to_tlbr()\n",
    "            class_name = track.get_class()\n",
    "            # draw bbox on screen\n",
    "            color = colors[int(track.track_id) % len(colors)]\n",
    "            color = [i * 255 for i in color]\n",
    "            x1, y1, x2, y2 = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "            x,y = int(np.ceil((x1+x2)/2)), int(np.ceil((y1+y2)/2)) \n",
    "\n",
    "            cv2.circle(frame, (x, y), 4, color, -1)\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1)\n",
    "            cv2.putText(frame, class_name + \"-\" + str(track.track_id),(int(bbox[0]), int(bbox[1]-10)),0, 0.75, (255,255,255),2)\n",
    "   \n",
    "            cr_xy.append((x,y))\n",
    "            cr_lbl.append(class_name)\n",
    "\n",
    "\n",
    "        if(len(pv_1_xy)>0):\n",
    "            if len(cr_lbl)<len(pv_1_lbl):\n",
    "                idx = [pv_1_lbl.index(i) for i in cr_lbl if i in pv_1_lbl]\n",
    "                c_x = [pv_1_xy[i] for i in idx]\n",
    "                res = list(np.linalg.norm(np.array(cr_xy)-np.array(c_x),axis=1))\n",
    "                wnd_lbl.append(cr_lbl)\n",
    "                wnd_xy.append(res)\n",
    "\n",
    "            else:\n",
    "                idx = [cr_lbl.index(i) for i in pv_1_lbl if i in cr_lbl]\n",
    "                c_x = [cr_xy[i] for i in idx]\n",
    "                res = list(np.linalg.norm(np.array(pv_1_xy)-np.array(c_x),axis=1))\n",
    "                wnd_lbl.append([cr_lbl[i] for i in idx])\n",
    "                wnd_xy.append(res)\n",
    "                \n",
    "            if len(wnd_lbl)>2:\n",
    "                del wnd_lbl[0]\n",
    "                del wnd_xy[0]          \n",
    "                \n",
    "                cmn = [i for i in wnd_lbl[-1] if i in wnd_lbl[-2]]\n",
    "                a1_idx,a2_idx = [wnd_lbl[-1].index(i) for i in cmn], [wnd_lbl[-2].index(i) for i in cmn]\n",
    "                a_1 = [wnd_lbl[-1][i] for i in a1_idx], [wnd_lbl[-2][i] for i in a2_idx]\n",
    "                b_1 = [wnd_xy[-1][i] for i in a1_idx], [wnd_xy[-2][i] for i in a2_idx]\n",
    "                res = list(np.sum(b_1, axis=0))\n",
    "                for i in range(len(res)):\n",
    "                    if res[i]>7:\n",
    "                        cv2.putText(frame, \"m:{} d:{:.2f}\".format(wnd_lbl[-1][i], res[i]),(5, 35), 0, 1.5, (0,255,0),2)\n",
    "                \n",
    "                bal = [\"sld m:{} d:{:.2f}\".format(wnd_lbl[-1][i], res[i]) for i in range(len(res)) if res[i]>7]\n",
    "                print(frame_num,bal)\n",
    "                \n",
    "        pv_1_xy = cr_xy   \n",
    "        pv_1_lbl = cr_lbl\n",
    "        \n",
    "        result = np.asarray(frame)\n",
    "             \n",
    "        fps.update()  \n",
    "        cv2.putText(frame,str(frame_num),(10,60),0,1.5,(0,255,255),1)\n",
    "        frame_num+=1 \n",
    "        out.write(frame)\n",
    "        cv2.namedWindow(\"result\", cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow(\"result\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "    else:\n",
    "        break              \n",
    "vid.release()  \n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "fps.stop()\n",
    "print(\"Elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"FPS: {:.2f}\".format(fps.fps()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
