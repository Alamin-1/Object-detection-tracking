{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import os\n",
    "# comment out below line to enable tensorflow logging outputs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import time\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import core.utils as utils\n",
    "from core.yolov4 import filter_boxes\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from core.config import cfg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from imutils.video import FPS\n",
    "# deep sort imports\n",
    "from deep_sort import preprocessing, nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from tools import generate_detections as gdet\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(anchors_path):\n",
    "    anchors = np.array(anchors_path)\n",
    "    return anchors.reshape(3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(FLAGS):\n",
    "    STRIDES = np.array(cfg.YOLO.STRIDES)\n",
    "    if FLAGS == 'yolov4':\n",
    "        ANCHORS = get_anchors(cfg.YOLO.ANCHORS)\n",
    "    XYSCALE = cfg.YOLO.XYSCALE\n",
    "    NUM_CLASS = len(utils.read_class_names(cfg.YOLO.CLASSES))\n",
    "    return STRIDES, ANCHORS, NUM_CLASS, XYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "6 []\n",
      "7 []\n",
      "8 []\n",
      "9 []\n",
      "10 []\n",
      "11 []\n",
      "12 []\n",
      "13 []\n",
      "14 []\n",
      "15 []\n",
      "16 []\n",
      "17 []\n",
      "18 []\n",
      "19 []\n",
      "20 []\n",
      "21 []\n",
      "22 []\n",
      "23 []\n",
      "24 []\n",
      "25 []\n",
      "26 []\n",
      "27 []\n",
      "28 []\n",
      "29 []\n",
      "30 []\n",
      "31 []\n",
      "32 []\n",
      "33 []\n",
      "34 []\n",
      "35 []\n",
      "36 []\n",
      "37 []\n",
      "38 []\n",
      "39 []\n",
      "40 []\n",
      "41 []\n",
      "42 []\n",
      "43 []\n",
      "44 []\n",
      "45 []\n",
      "46 []\n",
      "47 []\n",
      "48 []\n",
      "49 []\n",
      "50 []\n",
      "51 []\n",
      "52 []\n",
      "53 []\n",
      "54 []\n",
      "55 []\n",
      "56 []\n",
      "57 []\n",
      "58 []\n",
      "59 []\n",
      "60 []\n",
      "61 []\n",
      "62 []\n",
      "63 []\n",
      "64 []\n",
      "65 []\n",
      "66 []\n",
      "67 []\n",
      "68 []\n",
      "69 []\n",
      "70 []\n",
      "71 []\n",
      "72 []\n",
      "73 []\n",
      "74 []\n",
      "75 []\n",
      "76 []\n",
      "77 []\n",
      "78 []\n",
      "79 []\n",
      "80 []\n",
      "81 []\n",
      "82 []\n",
      "83 []\n",
      "84 []\n",
      "85 []\n",
      "86 []\n",
      "87 []\n",
      "88 []\n",
      "89 []\n",
      "90 []\n",
      "91 []\n",
      "92 []\n",
      "93 []\n",
      "94 []\n",
      "95 []\n",
      "96 []\n",
      "97 []\n",
      "98 []\n",
      "99 []\n",
      "100 []\n",
      "101 []\n",
      "102 []\n",
      "103 []\n",
      "104 []\n",
      "105 []\n",
      "106 []\n",
      "107 ['m:X-controller d:8.54']\n",
      "108 ['m:X-controller d:6.00']\n",
      "109 ['m:X-controller d:6.08']\n",
      "110 ['m:X-controller d:6.00']\n",
      "111 ['m:X-controller d:4.12']\n",
      "112 ['m:X-controller d:3.61']\n",
      "113 ['m:X-controller d:4.12']\n",
      "114 ['m:X-controller d:3.16']\n",
      "115 ['m:X-controller d:3.16']\n",
      "116 []\n",
      "117 ['m:X-controller d:3.16']\n",
      "118 []\n",
      "119 ['m:X-controller d:3.16']\n",
      "120 ['m:X-controller d:4.12']\n",
      "121 ['m:X-controller d:4.00']\n",
      "122 []\n",
      "123 []\n",
      "124 []\n",
      "125 []\n",
      "126 []\n",
      "127 []\n",
      "128 []\n",
      "129 []\n",
      "130 []\n",
      "131 []\n",
      "132 []\n",
      "133 []\n",
      "134 []\n",
      "135 []\n",
      "136 []\n",
      "137 []\n",
      "138 []\n",
      "139 []\n",
      "140 []\n",
      "141 []\n",
      "142 []\n",
      "143 []\n",
      "144 []\n",
      "145 []\n",
      "146 []\n",
      "147 []\n",
      "148 []\n",
      "149 []\n",
      "150 []\n",
      "151 []\n",
      "152 []\n",
      "153 []\n",
      "154 []\n",
      "155 []\n",
      "156 []\n",
      "157 []\n",
      "158 []\n",
      "159 []\n",
      "160 []\n",
      "161 []\n",
      "162 []\n",
      "163 []\n",
      "164 []\n",
      "165 []\n",
      "166 []\n",
      "167 []\n",
      "168 []\n",
      "169 []\n",
      "170 []\n",
      "171 []\n",
      "172 []\n",
      "173 []\n",
      "174 []\n",
      "175 []\n",
      "176 []\n",
      "177 []\n",
      "178 []\n"
     ]
    }
   ],
   "source": [
    "max_cosine_distance = 0.4\n",
    "nn_budget = None\n",
    "nms_max_overlap = 1.0\n",
    "with open(\"data/classes/cus_tracking.names\", \"r\", encoding='utf-8') as f: # tracking only few specific objects\n",
    "    tracked_classes = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_new_1.avi', fourcc, 20.0, (640,480))    \n",
    "    \n",
    "class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
    "# initialize deep sort model\n",
    "model_filename = 'model_data/mars-small128.pb'\n",
    "encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "# calculate cosine distance metric\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "# initialize tracker\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "\n",
    "# load configuration for object detector\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "STRIDES, ANCHORS, NUM_CLASS, XYSCALE = load_config('yolov4')\n",
    "input_size = 416\n",
    "\n",
    "video_path = './data/cut_1.mp4' #Input video file\n",
    "vid = cv2.VideoCapture(video_path)\n",
    "\n",
    "#Loading the trained weights for object detection algorithm\n",
    "saved_model_loaded = tf.saved_model.load('./checkpoints/yolov4-416', tags=[tag_constants.SERVING])\n",
    "infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "\n",
    "ref_frm,ref_frm_lbl,store = [],[],[],\n",
    "frame_num = 0\n",
    "fps = FPS().start()\n",
    "while True:\n",
    "    grabbed, frame = vid.read()\n",
    "    if grabbed==True:\n",
    "        image = Image.fromarray(frame)\n",
    "        frame_size = frame.shape[:2]\n",
    "        image_data = cv2.resize(frame, (input_size, input_size))\n",
    "        image_data = image_data / 255.\n",
    "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "        start_time = time.time()\n",
    "        batch_data = tf.constant(image_data)\n",
    "        pred_bbox = infer(batch_data)\n",
    "        for key, value in pred_bbox.items():\n",
    "            boxes = value[:, :, 0:4]\n",
    "            pred_conf = value[:, :, 4:]\n",
    "\n",
    "        boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "            boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "            scores=tf.reshape(\n",
    "                pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "            max_output_size_per_class=50,\n",
    "            max_total_size=50,\n",
    "            iou_threshold=0.45,\n",
    "            score_threshold=0.5)    \n",
    "\n",
    "        # convert data to numpy arrays and slice out unused elements\n",
    "        num_objects = valid_detections.numpy()[0]\n",
    "        bboxes = boxes.numpy()[0]\n",
    "        bboxes = bboxes[0:int(num_objects)]\n",
    "        scores = scores.numpy()[0]\n",
    "        scores = scores[0:int(num_objects)]\n",
    "        classes = classes.numpy()[0]\n",
    "        classes = classes[0:int(num_objects)]\n",
    "\n",
    "        # format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n",
    "        original_h, original_w, _ = frame.shape\n",
    "        bboxes = utils.format_boxes(bboxes, original_h, original_w)\n",
    "\n",
    "        # store all predictions in one parameter for simplicity when calling functions\n",
    "        pred_bbox = [bboxes, scores, classes, num_objects]\n",
    "        names, deleted_indx = [], []\n",
    "        for i in range(num_objects):\n",
    "            class_indx = int(classes[i])\n",
    "            class_name = class_names[class_indx]\n",
    "            if class_name not in tracked_classes:\n",
    "                deleted_indx.append(i)\n",
    "            else:\n",
    "                names.append(class_name)\n",
    "        names = np.array(names)\n",
    "        count = len(names)\n",
    "#         print(\"Objects being tracked: {}\".format(count))\n",
    "\n",
    "        # delete detections that are not in tracked_classes\n",
    "        bboxes = np.delete(bboxes, deleted_indx, axis=0)\n",
    "        scores = np.delete(scores, deleted_indx, axis=0)\n",
    "\n",
    "        # encode yolo detections and feed to tracker\n",
    "        features = encoder(frame, bboxes)\n",
    "        detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n",
    "\n",
    "\n",
    "        #initialize color map\n",
    "        cmap = plt.get_cmap('tab20b')\n",
    "        colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "        # run non-maxima supression\n",
    "        boxs = np.array([d.tlwh for d in detections])\n",
    "        scores = np.array([d.confidence for d in detections])\n",
    "        classes = np.array([d.class_name for d in detections])\n",
    "        indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "        detections = [detections[i] for i in indices]\n",
    "\n",
    "        # Call the tracker\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "        # update tracks\n",
    "        cur_frm,cur_frm_lbl = [],[]\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            bbox = track.to_tlbr()\n",
    "            class_name = track.get_class()\n",
    "            # draw bbox on screen\n",
    "            color = colors[int(track.track_id) % len(colors)]\n",
    "            color = [i * 255 for i in color]\n",
    "            x1, y1, x2, y2 = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "            x,y = int(np.ceil((x1+x2)/2)), int(np.ceil((y1+y2)/2)) #getting the center coordinates of detected objects\n",
    "\n",
    "            cv2.circle(frame, (x, y), 4, color, -1)\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1)\n",
    "            cv2.putText(frame, class_name + \"-\" + str(track.track_id),(int(bbox[0]), int(bbox[1]-10)),0, 0.75, (255,255,255),2)\n",
    "   \n",
    "            cur_frm.append((x,y))\n",
    "            cur_frm_lbl.append(class_name)\n",
    "\n",
    "        #Addressing the issue missmatch of detected objects in two frames\n",
    "        if(len(ref_frm)>0):\n",
    "            if len(cur_frm_lbl)<len(ref_frm_lbl):\n",
    "                idx = [ref_frm_lbl.index(i) for i in cur_frm_lbl if i in ref_frm_lbl]\n",
    "                c_x = [ref_frm[i] for i in idx]\n",
    "                res = list(np.linalg.norm(np.array(cur_frm)-np.array(c_x),axis=1))\n",
    "                for i in range(len(res)):\n",
    "                    if res[i]>3:\n",
    "                        cv2.putText(frame, \"m:{} d:{:.2f}\".format(cur_frm_lbl[i], res[i]),(5, 35), 0, 1.5, (0,255,0),2)\n",
    "                bal = [\"m:{} d:{:.2f}\".format(cur_frm_lbl[i], res[i]) for i in range(len(res)) if res[i]>3]\n",
    "                print(frame_num, bal)\n",
    "                        \n",
    "            else:\n",
    "                idx = [cur_frm_lbl.index(i) for i in ref_frm_lbl if i in cur_frm_lbl]\n",
    "                c_x = [cur_frm[i] for i in idx]\n",
    "                res = list(np.linalg.norm(np.array(ref_frm)-np.array(c_x),axis=1))\n",
    "                for i in range(len(res)):\n",
    "                    if res[i]>3:\n",
    "                        cv2.putText(frame, \"m:{} d:{:.2f}\".format(cur_frm_lbl[i], res[i]),(5, 35), 0, 1.5, (0,255,0),2)\n",
    "                bal = [\"m:{} d:{:.2f}\".format(cur_frm_lbl[i], res[i]) for i in range(len(res)) if res[i]>3]\n",
    "                print(frame_num, bal)\n",
    "                        \n",
    "        #Updating the reference frame (co-ordinates and labels)\n",
    "        ref_frm = cur_frm   \n",
    "        ref_frm_lbl = cur_frm_lbl\n",
    "        result = np.asarray(frame)\n",
    "             \n",
    "        fps.update()  \n",
    "        cv2.putText(frame,str(frame_num),(10,60),0,1.5,(0,255,255),1)\n",
    "        frame_num+=1 \n",
    "        out.write(frame)\n",
    "        cv2.namedWindow(\"result\", cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow(\"result\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "    else:\n",
    "        break              \n",
    "vid.release()  \n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "fps.stop()\n",
    "print(\"Elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"FPS: {:.2f}\".format(fps.fps()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if a[-1]>a[-2]\n",
    "cr_lbl,pv_1_lbl = ['Workpiece', 'X-controller', 'xyz'], ['Spindle holder', 'Workpiece', 'X-controller', 'abc']\n",
    "cr_xy,pv_1_xy = [(0,0),(0,0),(0,0)], [(0,0),(0,1),(1,1),(0,2),(0,3)]\n",
    "\n",
    "cmn = [i for i in cr_lbl if i in pv_1_lbl]\n",
    "cr_idx, pv_idx = [cr_lbl.index(i) for i in cmn], [pv_1_lbl.index(i) for i in cmn]\n",
    "cr_lbl1, pv_1_lbl1 = [cr_lbl[i] for i in cr_idx], [pv_1_lbl[i] for i in pv_idx]\n",
    "cr_xy1, pv_1_xy1 = [cr_xy[i] for i in cr_idx], [pv_1_xy[i] for i in pv_idx]\n",
    "\n",
    "res = list(np.linalg.norm(np.array(cr_xy1)-np.array(pv_1_xy1),axis=1))\n",
    "\n",
    "print(cr_xy1, pv_1_xy1)\n",
    "print(pv_1_lbl1)\n",
    "\n",
    "# print(cr_lbl1, pv_1_lbl1)\n",
    "# res = list(np.sum(b_1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3.345654\n",
    "print('val:{:.2f}'.format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['X-controller', (40, 408)]\n",
    "b = [['X-controller', (41, 410)], ['X-controller', (41, 410)]]\n",
    "mx = max(len(a),len(b))\n",
    "for i in range(2):\n",
    "    if b[i]==a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnd_lbl,wnd_xy = [], []\n",
    "cr_lbl,cr_xy = ['a','b','c'], [(0,0),(0,0),(0,0)]\n",
    "pv_1_lbl,pv_1_xy = ['x','a','y','b','c'], [(0,0),(0,1),(1,1),(0,2),(0,3)]\n",
    "\n",
    "\n",
    "if len(cr_lbl)<len(pv_1_lbl):\n",
    "    idx = [pv_1_lbl.index(i) for i in cr_lbl if i in pv_1_lbl]\n",
    "    c_x = [pv_1_xy[i] for i in idx]\n",
    "    res = list(np.linalg.norm(np.array(cr_xy)-np.array(c_x),axis=1))\n",
    "    wnd_lbl.append(cr_lbl)\n",
    "    wnd_xy.append(res)\n",
    "\n",
    "#     for i in range(len(res)):\n",
    "#         if res[i]>3:\n",
    "#             cv2.putText(frame, \"m:{} d:{:.2f}\".format(cr_lbl[i], res[i]),(5, 35), 0, 1.5, (0,255,0),2)\n",
    "#     bal = [\"pv1 m:{} d:{:.2f}\".format(cr_lbl[i], res[i]) for i in range(len(res)) if res[i]>3]\n",
    "#     print(bal)\n",
    "else:\n",
    "    idx = [cr_lbl.index(i) for i in pv_1_lbl if i in cr_lbl]\n",
    "    c_x = [cr_xy[i] for i in idx]\n",
    "    res = list(np.linalg.norm(np.array(pv_1_xy)-np.array(c_x),axis=1))\n",
    "    wnd_lbl.append([cr_lbl[i] for i in idx])\n",
    "    wnd_xy.append(res)\n",
    "#     for i in range(len(res)):\n",
    "#         if res[i]>3:\n",
    "#             cv2.putText(frame, \"m:{} d:{:.2f}\".format(cr_lbl[i], res[i]),(5, 35), 0, 1.5, (0,255,0),2)\n",
    "#     bal = [\"pv1 m:{} d:{:.2f}\".format(cr_lbl[i], res[i]) for i in range(len(res)) if res[i]>3]\n",
    "#     print(bal) \n",
    "\n",
    "\n",
    "print(wnd_lbl,wnd_xy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(0,0),(0,0),(0,0)]\n",
    "b = [(0,1),(0,2),(0,3)]\n",
    "\n",
    "res = np.linalg.norm(np.array(a)-np.array(b), axis=1)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(a[1])\n",
    "y = np.array(b[1])\n",
    "\n",
    "res = np.linalg.norm(x-y)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = [[0,0],[0,0],[0,0],[0,0],[0,0]]\n",
    "all(len(m)==len(ex[0]) for m in ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = [[1, 2, 3], [1, 2, 3], [1, 2, 3]]\n",
    "tst = np.array(tst)\n",
    "tst = list(np.sum(tst, axis=0))\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(1, 1),(168, 294)]\n",
    "b = [(0, 0),(158, 236)]\n",
    "mn = min(len(a),len(b))\n",
    "m = np.array(a)\n",
    "n = np.array(b)\n",
    "\n",
    "res = np.linalg.norm(m-n, axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[165, 302], [168, 294], [168, 288],[167, 282],[167, 276],[166, 272],[164, 269],[163, 265],[162, 262],[161, 259],\n",
    "      [161, 256],[160, 253],[161, 251],[160, 248],[161, 244],[161, 240],[161, 238],[161, 236],[160, 235],[159, 236],\n",
    "       [158, 236],[158, 237],[159, 236],[158, 236],[159, 236]]\n",
    "\n",
    "for i in range(len(lst)-1):\n",
    "    a = np.array(lst[i])\n",
    "    b = np.array(lst[i+1])\n",
    "    dis = np.linalg.norm(a-b)\n",
    "    print(a,b,dis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:/Desktop/OD/custom_data/images')\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "ffmpeg_extract_subclip('try_6_above.avi',215,220,'cut_1.mp4')\n",
    "os.chdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance =[0,5,7]\n",
    "[playsound('audio.mp3') for i in distance if i>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lbl_idx:\n",
    "    print(distance[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([(1,2), (3,6)])\n",
    "b = np.array([(0,0), (0,0)])\n",
    "# a-b\n",
    "dis = np.linalg.norm(a-b, axis=1)\n",
    "dis = list(dis)\n",
    "print(type(dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} and {}'.format(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([(1,2)])\n",
    "b = np.array([])\n",
    "# a-b\n",
    "dis = np.linalg.norm(a-b, axis=1)\n",
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 7, 9]\n",
    "window_size = 3\n",
    "\n",
    "i = 0\n",
    "moving_averages = []\n",
    "while i < len(numbers) - window_size + 1:\n",
    "    this_window = numbers[i : i + window_size]\n",
    "get current window\n",
    "\n",
    "    window_average = sum(this_window) / window_size\n",
    "    moving_averages.append(window_average)\n",
    "    i += 1\n",
    "\n",
    "print(moving_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
